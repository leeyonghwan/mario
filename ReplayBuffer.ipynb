{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "class ReplayBuffer(object):\n",
    "    def __init__(self, size, frame_history_len):\n",
    "        \"\"\"This is a memory efficient implementation of the replay buffer.\n",
    "\n",
    "        The sepecific memory optimizations use here are:\n",
    "            - only store each frame once rather than k times\n",
    "              even if every observation normally consists of k last frames\n",
    "            - store frames as np.uint8 (actually it is most time-performance\n",
    "              to cast them back to float32 on GPU to minimize memory transfer\n",
    "              time)\n",
    "            - store frame_t and frame_(t+1) in the same buffer.\n",
    "\n",
    "        For the typical use case in Atari Deep RL buffer with 1M frames the total\n",
    "        memory footprint of this buffer is 10^6 * 84 * 84 bytes ~= 7 gigabytes\n",
    "\n",
    "        Warning! Assumes that returning frame of zeros at the beginning\n",
    "        of the episode, when there is less frames than `frame_history_len`,\n",
    "        is acceptable.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        size: int\n",
    "            Max number of transitions to store in the buffer. When the buffer\n",
    "            overflows the old memories are dropped.\n",
    "        frame_history_len: int\n",
    "            Number of memories to be retried for each observation.\n",
    "        \"\"\"\n",
    "        self.size = size\n",
    "        self.frame_history_len = frame_history_len\n",
    "\n",
    "        self.next_idx      = 0\n",
    "        self.num_in_buffer = 0\n",
    "\n",
    "        self.obs      = None\n",
    "        self.action   = None\n",
    "        self.reward   = None\n",
    "        self.done     = None\n",
    "\n",
    "    def can_sample(self, batch_size):\n",
    "        \"\"\"Returns true if `batch_size` different transitions can be sampled from the buffer.\"\"\"\n",
    "        return batch_size + 1 <= self.num_in_buffer\n",
    "\n",
    "    def _encode_sample(self, idxes):\n",
    "        obs_batch      = np.concatenate([self._encode_observation(idx)[None] for idx in idxes], 0)\n",
    "        act_batch      = self.action[idxes]\n",
    "        rew_batch      = self.reward[idxes]\n",
    "        next_obs_batch = np.concatenate([self._encode_observation(idx + 1)[None] for idx in idxes], 0)\n",
    "        done_mask      = np.array([1.0 if self.done[idx] else 0.0 for idx in idxes], dtype=np.float32)\n",
    "\n",
    "        return obs_batch, act_batch, rew_batch, next_obs_batch, done_mask\n",
    "\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        \"\"\"Sample `batch_size` different transitions.\n",
    "\n",
    "        i-th sample transition is the following:\n",
    "\n",
    "        when observing `obs_batch[i]`, action `act_batch[i]` was taken,\n",
    "        after which reward `rew_batch[i]` was received and subsequent\n",
    "        observation  next_obs_batch[i] was observed, unless the epsiode\n",
    "        was done which is represented by `done_mask[i]` which is equal\n",
    "        to 1 if episode has ended as a result of that action.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        batch_size: int\n",
    "            How many transitions to sample.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        obs_batch: np.array\n",
    "            Array of shape\n",
    "            (batch_size, img_h, img_w, img_c * frame_history_len)\n",
    "            and dtype np.uint8\n",
    "        act_batch: np.array\n",
    "            Array of shape (batch_size,) and dtype np.int32\n",
    "        rew_batch: np.array\n",
    "            Array of shape (batch_size,) and dtype np.float32\n",
    "        next_obs_batch: np.array\n",
    "            Array of shape\n",
    "            (batch_size, img_h, img_w, img_c * frame_history_len)\n",
    "            and dtype np.uint8\n",
    "        done_mask: np.array\n",
    "            Array of shape (batch_size,) and dtype np.float32\n",
    "        \"\"\"\n",
    "        assert self.can_sample(batch_size)\n",
    "        idxes = sample_n_unique(lambda: random.randint(0, self.num_in_buffer - 2), batch_size)\n",
    "        return self._encode_sample(idxes)\n",
    "\n",
    "    def encode_recent_observation(self):\n",
    "        \"\"\"Return the most recent `frame_history_len` frames.\n",
    "        Returns\n",
    "        -------\n",
    "        observation: np.array\n",
    "            Array of shape (img_h, img_w, img_c * frame_history_len)\n",
    "            and dtype np.uint8, where observation[:, :, i*img_c:(i+1)*img_c]\n",
    "            encodes frame at time `t - frame_history_len + i`\n",
    "        \"\"\"\n",
    "        assert self.num_in_buffer > 0\n",
    "        return self._encode_observation(self.next_idx % self.size)\n",
    "\n",
    "    def _encode_observation(self, idx):\n",
    "        end_idx   = idx + 1 # make noninclusive\n",
    "        start_idx = end_idx - self.frame_history_len\n",
    "        # this checks if we are using low-dimensional observations, such as RAM\n",
    "        # state, in which case we just directly return the latest RAM.\n",
    "        if len(self.obs.shape) == 2:\n",
    "            return self.obs[end_idx-1]\n",
    "        # if there weren't enough frames ever in the buffer for context\n",
    "        if start_idx < 0 and self.num_in_buffer != self.size:\n",
    "            start_idx = 0\n",
    "        for idx in range(start_idx, end_idx - 1):\n",
    "            if self.done[idx % self.size]:\n",
    "                start_idx = idx + 1\n",
    "        missing_context = self.frame_history_len - (end_idx - start_idx)\n",
    "        # if zero padding is needed for missing context\n",
    "        # or we are on the boundry of the buffer\n",
    "        if start_idx < 0 or missing_context > 0:\n",
    "            frames = [np.zeros_like(self.obs[0]) for _ in range(missing_context)]\n",
    "            for idx in range(start_idx, end_idx):\n",
    "                frames.append(self.obs[idx % self.size])\n",
    "            return np.concatenate(frames, 2)\n",
    "        else:\n",
    "            # this optimization has potential to saves about 30% compute time \\o/\n",
    "            img_h, img_w = self.obs.shape[1], self.obs.shape[2]\n",
    "            return self.obs[start_idx:end_idx].transpose(1, 2, 0, 3).reshape(img_h, img_w, -1)\n",
    "\n",
    "    def store_frame(self, frame):\n",
    "        \"\"\"Store a single frame in the buffer at the next available index, overwriting\n",
    "        old frames if necessary.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        frame: np.array\n",
    "            Array of shape (img_h, img_w, img_c) and dtype np.uint8\n",
    "            the frame to be stored\n",
    "        \"\"\"\n",
    "        if self.obs is None:\n",
    "            self.obs      = np.empty([self.size] + list(frame.shape), dtype=np.uint8)\n",
    "            self.action   = np.empty([self.size],                     dtype=np.int32)\n",
    "            self.reward   = np.empty([self.size],                     dtype=np.float32)\n",
    "            self.done     = np.empty([self.size],                     dtype=np.bool)\n",
    "        self.obs[self.next_idx] = frame\n",
    "\n",
    "        if self.num_in_buffer < self.size:\n",
    "            self.num_in_buffer += 1\n",
    "\n",
    "    def store_effect(self, action, reward, done):\n",
    "        \"\"\"Store effects of action taken after obeserving frame stored\n",
    "        at index idx. The reason `store_frame` and `store_effect` is broken\n",
    "        up into two functions is so that once can call `encode_recent_observation`\n",
    "        in between.\n",
    "\n",
    "        Paramters\n",
    "        ---------\n",
    "        action: int\n",
    "            Action that was performed upon observing this frame.\n",
    "        reward: float\n",
    "            Reward that was received when the actions was performed.\n",
    "        done: bool\n",
    "            True if episode was finished after performing that action.\n",
    "        \"\"\"\n",
    "        self.action[self.next_idx] = action\n",
    "        self.reward[self.next_idx] = reward\n",
    "        self.done[self.next_idx]   = done\n",
    "        self.next_idx = (self.next_idx + 1) % self.size\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
